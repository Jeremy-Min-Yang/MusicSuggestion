{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1tJS3zhjqY1TvwcyGjT3AT88ya84S6ysf",
      "authorship_tag": "ABX9TyO/2oeepOYHkSh7Rho3OvKB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jeremy-Min-Yang/MusicSuggestion/blob/main/music_suggestion.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**GRABBING THE DATASET**"
      ],
      "metadata": {
        "id": "INjrJLaPPhc6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wXlsIdUoHXdZ",
        "outputId": "5c61f755-143a-4c08-aa69-e633bc1bf31b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "file_path = '/content/drive/My Drive/Colab Notebooks/data/dataset.csv'\n",
        "music_data = pd.read_csv(file_path)\n"
      ],
      "metadata": {
        "id": "2Au4kv8AlryS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**DATA PREPROCESSING**"
      ],
      "metadata": {
        "id": "6x_Xy-OwPbT3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Select relevant columns for preprocessing\n",
        "selected_columns = [\n",
        "    'track_id', 'track_name', 'artists', 'track_genre',\n",
        "    'danceability', 'energy', 'valence', 'tempo',\n",
        "    'acousticness', 'popularity'\n",
        "]\n",
        "preprocessed_dataset = music_data[selected_columns]\n",
        "\n",
        "# Check for missing values and drop rows with missing data\n",
        "preprocessed_dataset = preprocessed_dataset.dropna()\n",
        "\n",
        "# Normalize numerical features\n",
        "scaler = MinMaxScaler()\n",
        "numerical_features = ['danceability', 'energy', 'valence', 'tempo', 'acousticness', 'popularity']\n",
        "preprocessed_dataset[numerical_features] = scaler.fit_transform(preprocessed_dataset[numerical_features])\n",
        "\n",
        "# Check for duplicates and drop them\n",
        "preprocessed_dataset = preprocessed_dataset.drop_duplicates()\n",
        "\n",
        "# Save preprocessed dataset to a new CSV file\n",
        "output_path = 'preprocessed_spotify_dataset.csv'  # Change to your desired output path\n",
        "preprocessed_dataset.to_csv(output_path, index=False)\n",
        "\n",
        "print(f\"Preprocessed dataset saved to {output_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tM_YAun9zyXl",
        "outputId": "14ec83f2-9590-4682-f61e-b8d0ae6adf98"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Preprocessed dataset saved to preprocessed_spotify_dataset.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TRAINING USER INPUT PROCESSING MODEL**"
      ],
      "metadata": {
        "id": "enDmoiHvdiy5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = '/content/drive/My Drive/Colab Notebooks/data/Categorized_Sentences.csv'\n",
        "input_data = pd.read_csv(file_path)"
      ],
      "metadata": {
        "id": "bO5Wu8ajdifG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "use different classification models/vectorization tecniques (tf-df/count-vectorizer)"
      ],
      "metadata": {
        "id": "EZoiU5IFSvXz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "import joblib\n",
        "\n",
        "# Drop rows with missing values\n",
        "input_data = input_data.dropna()\n",
        "\n",
        "# Preprocess text\n",
        "input_data['Phrase'] = input_data['Phrase'].str.lower()\n",
        "\n",
        "# Split into training and testing sets\n",
        "X = input_data['Phrase']\n",
        "y = input_data['Category']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Vectorize the text\n",
        "vectorizer = CountVectorizer()\n",
        "X_train_vec = vectorizer.fit_transform(X_train)\n",
        "X_test_vec = vectorizer.transform(X_test)\n",
        "\n",
        "# Train the model\n",
        "clf = RandomForestClassifier(random_state=42)\n",
        "clf.fit(X_train_vec, y_train)\n",
        "\n",
        "# Evaluate the model\n",
        "y_pred = clf.predict(X_test_vec)\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Save the model and vectorizer\n",
        "joblib.dump(clf, 'phrase_classifier.pkl')\n",
        "joblib.dump(vectorizer, 'vectorizer.pkl')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sLtEzVW8R03e",
        "outputId": "62c720b9-5fd6-4ee1-906e-b89920352cb9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-abd138fcdb71>:12: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  input_data['Phrase'] = input_data['Phrase'].str.lower()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    activity       0.69      0.60      0.64        15\n",
            "    location       0.71      0.79      0.75        19\n",
            "        mood       0.90      0.90      0.90        20\n",
            "     weather       0.92      0.92      0.92        26\n",
            "\n",
            "    accuracy                           0.82        80\n",
            "   macro avg       0.81      0.80      0.80        80\n",
            "weighted avg       0.82      0.82      0.82        80\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['vectorizer.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Train a Logistic Regression model\n",
        "log_reg = LogisticRegression(random_state=42, max_iter=1000)\n",
        "log_reg.fit(X_train_vec, y_train)\n",
        "\n",
        "# Evaluate the model\n",
        "y_pred = log_reg.predict(X_test_vec)\n",
        "print(classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WGi-Kdr2cOyD",
        "outputId": "2ce94d96-9607-4325-97b4-c8224a121680"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    activity       0.80      0.80      0.80        15\n",
            "    location       0.83      0.79      0.81        19\n",
            "        mood       0.85      0.85      0.85        20\n",
            "     weather       0.89      0.92      0.91        26\n",
            "\n",
            "    accuracy                           0.85        80\n",
            "   macro avg       0.84      0.84      0.84        80\n",
            "weighted avg       0.85      0.85      0.85        80\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Transform text into TF-IDF features\n",
        "tfidf_vectorizer = TfidfVectorizer(max_features=5000)\n",
        "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
        "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
        "\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "# Train an MLPClassifier\n",
        "mlp_model = MLPClassifier(random_state=42, hidden_layer_sizes=(100, 50), max_iter=500)\n",
        "mlp_model.fit(X_train_tfidf, y_train)\n",
        "\n",
        "# Evaluate the model\n",
        "y_pred = mlp_model.predict(X_test_tfidf)\n",
        "print(classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EQAuCuwpca0i",
        "outputId": "600ae598-0f3f-4421-f5d2-261ca21a579c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    activity       0.65      0.73      0.69        15\n",
            "    location       0.78      0.74      0.76        19\n",
            "        mood       0.95      0.90      0.92        20\n",
            "     weather       0.96      0.96      0.96        26\n",
            "\n",
            "    accuracy                           0.85        80\n",
            "   macro avg       0.83      0.83      0.83        80\n",
            "weighted avg       0.86      0.85      0.85        80\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**PROCESSING USER INPUT INTO ENVIRONMENT/EMOTION**"
      ],
      "metadata": {
        "id": "GwKvlIJBQv-g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "\n",
        "# Load trained model and vectorizer\n",
        "phrase_classifier = joblib.load('phrase_classifier.pkl')\n",
        "vectorizer = joblib.load('vectorizer.pkl')\n",
        "\n",
        "def classify_sentences(sentences):\n",
        "    # Vectorize sentences for classification\n",
        "    sentences_vec = vectorizer.transform(sentences)\n",
        "    predictions = phrase_classifier.predict(sentences_vec)\n",
        "    return predictions\n",
        "\n",
        "def process_user_input_with_model(user_input):\n",
        "    # Use SpaCy for sentence segmentation\n",
        "    doc = nlp(user_input)\n",
        "    sentences = [sentence.text for sentence in doc.sents]\n",
        "\n",
        "    # Classify each sentence\n",
        "    predictions = classify_sentences(sentences)\n",
        "\n",
        "    # Group sentences by predicted category\n",
        "    environment = {\"weather\": [], \"activity\": [], \"location\": []}\n",
        "    mood = []\n",
        "\n",
        "    for sentence, prediction in zip(sentences, predictions):\n",
        "        if prediction == \"mood\":\n",
        "            mood.append(sentence)\n",
        "        elif prediction in environment:\n",
        "            environment[prediction].append(sentence)\n",
        "\n",
        "    # Combine sentences into strings\n",
        "    mood_text = \" \".join(mood)\n",
        "    for key in environment:\n",
        "        environment[key] = \" \".join(environment[key])\n",
        "\n",
        "    return environment, mood_text\n"
      ],
      "metadata": {
        "id": "HHxOfPd4Kkiq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**EXTRACT ENTITIES AND KEYWORDS**"
      ],
      "metadata": {
        "id": "9fX6W8btRDKC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**WEATHER KEYWORDS/ACTIVITY KEYWORDS ARE HARDCODED LISTS AND NARROW DOWN THE SCOPE**\n",
        "\n",
        "ALTERNATIVE: TRAIN OUR OWN MODEL"
      ],
      "metadata": {
        "id": "awKM1ih6bYfJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import spacy\n",
        "# from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "\n",
        "\n",
        "# # Load SpaCy and sentiment analysis tools\n",
        "# nlp = spacy.load(\"en_core_web_sm\")\n",
        "# sid = SentimentIntensityAnalyzer()\n",
        "\n",
        "# # List of weather keywords and activities for keyword matching\n",
        "# weather_keywords = [\"snowing\", \"raining\", \"sunny\", \"cloudy\", \"stormy\", \"windy\"]\n",
        "# activity_keywords = [\"walking\", \"running\", \"sitting\", \"driving\", \"working\", \"relaxing\"]\n",
        "\n",
        "# def extract_entities_and_keywords(user_input):\n",
        "#     # Process input with SpaCy\n",
        "#     doc = nlp(user_input)\n",
        "\n",
        "#     # Extract entities\n",
        "#     location = [ent.text for ent in doc.ents if ent.label_ in [\"GPE\", \"LOC\"]]  # Location\n",
        "#     time = [ent.text for ent in doc.ents if ent.label_ == \"TIME\"]             # Time\n",
        "#     date = [ent.text for ent in doc.ents if ent.label_ == \"DATE\"]             # Date\n",
        "\n",
        "#     # Extract keywords\n",
        "#     weather = [token.text for token in doc if token.text.lower() in weather_keywords]\n",
        "#     activity = [token.text for token in doc if token.text.lower() in activity_keywords]\n",
        "\n",
        "#     return location, time, date, weather, activity\n",
        "\n",
        "# def analyze_sentiment(user_input):\n",
        "#     # Use NLTK's VADER sentiment analyzer\n",
        "#     sentiment_scores = sid.polarity_scores(user_input)\n",
        "#     if sentiment_scores[\"compound\"] > 0.2:\n",
        "#         mood = \"positive\"\n",
        "#     elif sentiment_scores[\"compound\"] < -0.2:\n",
        "#         mood = \"negative\"\n",
        "#     else:\n",
        "#         mood = \"neutral\"\n",
        "#     return mood\n",
        "\n",
        "# def process_user_input(user_input):\n",
        "#     # Extract environment entities and keywords\n",
        "#     location, time, date, weather, activity = extract_entities_and_keywords(user_input)\n",
        "\n",
        "#     # Analyze sentiment for mood\n",
        "#     mood = analyze_sentiment(user_input)\n",
        "\n",
        "#     # Compile environment description\n",
        "#     environment = {\n",
        "#         \"location\": location,\n",
        "#         \"time\": time,\n",
        "#         \"date\": date,\n",
        "#         \"weather\": weather,\n",
        "#         \"activity\": activity\n",
        "#     }\n",
        "\n",
        "#     return environment, mood\n",
        "\n",
        "# # Process the input\n",
        "# environment, mood = process_user_input(user_input)\n",
        "\n",
        "# # Print results\n",
        "# print(\"Environment:\", environment)\n",
        "# print(\"Mood:\", mood)\n"
      ],
      "metadata": {
        "id": "hD1jkQgfRGZd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from spacy import displacy\n",
        "\n",
        "# def visualize_entities(user_input):\n",
        "#     doc = nlp(user_input)\n",
        "#     displacy.render(doc, style=\"ent\", jupyter=True)  # Visualize entities\n",
        "\n",
        "# def visualize_dependencies(user_input):\n",
        "#     doc = nlp(user_input)\n",
        "#     displacy.render(doc, style=\"dep\", jupyter=True)  # Visualize dependencies\n",
        "\n",
        "\n",
        "# # Call visualization functions\n",
        "# visualize_entities(user_input)  # View named entities\n",
        "# visualize_dependencies(user_input)  # View dependency tree\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "YAPsa5QcWCHx",
        "outputId": "16019c58-5385-4bae-c9b9-d67b64c555d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'user_input' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-a93721f3e621>\u001b[0m in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# Call visualization functions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mvisualize_entities\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_input\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# View named entities\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0mvisualize_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_input\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# View dependency tree\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'user_input' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def map_inputs_to_features(environment, mood):\n",
        "    # Initialize default feature values\n",
        "    features = {\n",
        "        \"valence\": 0.5,  # Neutral positivity\n",
        "        \"energy\": 0.5,   # Neutral energy\n",
        "        \"tempo\": 120,    # Moderate tempo\n",
        "        \"acousticness\": 0.5,  # Balanced acousticness\n",
        "        \"genre\": \"pop\",  # Default genre\n",
        "    }\n",
        "\n",
        "    # Map mood to valence and energy\n",
        "    if mood == \"positive\":\n",
        "        features[\"valence\"] = 0.8\n",
        "        features[\"energy\"] = 0.6\n",
        "    elif mood == \"negative\":\n",
        "        features[\"valence\"] = 0.3\n",
        "        features[\"energy\"] = 0.4\n",
        "    elif mood == \"neutral\":\n",
        "        features[\"valence\"] = 0.5\n",
        "        features[\"energy\"] = 0.5\n",
        "\n",
        "    # Map environment details\n",
        "    if \"snowing\" in environment[\"weather\"]:\n",
        "        features[\"acousticness\"] = 0.8\n",
        "        features[\"genre\"] = \"acoustic\"\n",
        "    elif \"raining\" in environment[\"weather\"]:\n",
        "        features[\"acousticness\"] = 0.7\n",
        "        features[\"genre\"] = \"ambient\"\n",
        "\n",
        "    if \"walking\" in environment[\"activity\"]:\n",
        "        features[\"tempo\"] = 100\n",
        "        features[\"energy\"] = 0.5\n",
        "    elif \"running\" in environment[\"activity\"]:\n",
        "        features[\"tempo\"] = 140\n",
        "        features[\"energy\"] = 0.8\n",
        "\n",
        "    return features"
      ],
      "metadata": {
        "id": "k3-ntGeZXgfg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# user_features = map_inputs_to_features(environment, mood)\n",
        "\n",
        "# print(\"Mapped Features:\", user_features)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "id": "eU3ist19XjK2",
        "outputId": "c97f3660-31b2-4ac4-c354-2129fd1358f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'environment' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-e9c83853fb22>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0muser_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap_inputs_to_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menvironment\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmood\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Mapped Features:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'environment' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def filter_songs(preprocessed_dataset, user_features):\n",
        "    filtered_songs = preprocessed_dataset[\n",
        "        (preprocessed_dataset[\"valence\"] >= user_features[\"valence\"] - 0.2) &\n",
        "        (preprocessed_dataset[\"valence\"] <= user_features[\"valence\"] + 0.2) &\n",
        "        (preprocessed_dataset[\"energy\"] >= user_features[\"energy\"] - 0.2) &\n",
        "        (preprocessed_dataset[\"energy\"] <= user_features[\"energy\"] + 0.2) &\n",
        "        (preprocessed_dataset[\"tempo\"] >= user_features[\"tempo\"] - 20) &\n",
        "        (preprocessed_dataset[\"tempo\"] <= user_features[\"tempo\"] + 20) &\n",
        "        (preprocessed_dataset[\"track_genre\"] == user_features[\"genre\"])\n",
        "    ]\n",
        "    return filtered_songs\n"
      ],
      "metadata": {
        "id": "gmcpoLm-XoCM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def recommend_songs(user_input, preprocessed_dataset):\n",
        "    # Process user input using the updated function\n",
        "    environment, mood = process_user_input_with_model(user_input)\n",
        "\n",
        "    # Map user inputs to feature values\n",
        "    user_features = map_inputs_to_features(environment, mood)\n",
        "    print(\"Mapped Features for Filtering:\", user_features)\n",
        "\n",
        "    # Filter songs from the dataset\n",
        "    recommendations = filter_songs(preprocessed_dataset, user_features).head(10)\n",
        "\n",
        "    # Handle case where no songs are found\n",
        "    if recommendations.empty:\n",
        "        print(\"No exact matches found. Recommending popular tracks instead.\")\n",
        "        recommendations = preprocessed_dataset.sort_values(by=\"popularity\", ascending=False).head(10)\n",
        "\n",
        "    return recommendations\n"
      ],
      "metadata": {
        "id": "oZCIm3nQXu4m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example user input\n",
        "user_input = \"I am feeling stressed after a long day. It's snowing and freezing outside in Boston.\"\n",
        "\n",
        "# Recommend songs\n",
        "recommended_songs = recommend_songs(user_input, preprocessed_dataset)\n",
        "\n",
        "# Display results\n",
        "print(\"Recommended Songs:\")\n",
        "print(recommended_songs[[\"track_name\", \"artists\", \"track_genre\", \"popularity\"]])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nTQZyGvRYRTC",
        "outputId": "6038b5db-c70f-4d35-95ad-4d007930b547"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mapped Features for Filtering: {'valence': 0.5, 'energy': 0.5, 'tempo': 120, 'acousticness': 0.8, 'genre': 'acoustic'}\n",
            "No exact matches found. Recommending popular tracks instead.\n",
            "Recommended Songs:\n",
            "                                  track_name                  artists  \\\n",
            "81051              Unholy (feat. Kim Petras)     Sam Smith;Kim Petras   \n",
            "20001              Unholy (feat. Kim Petras)     Sam Smith;Kim Petras   \n",
            "51664  Quevedo: Bzrp Music Sessions, Vol. 52         Bizarrap;Quevedo   \n",
            "68303                             La Bachata            Manuel Turizo   \n",
            "81210                        I'm Good (Blue)  David Guetta;Bebe Rexha   \n",
            "67356                             La Bachata            Manuel Turizo   \n",
            "88410                             La Bachata            Manuel Turizo   \n",
            "30003                        I'm Good (Blue)  David Guetta;Bebe Rexha   \n",
            "89411                             La Bachata            Manuel Turizo   \n",
            "20008                        I'm Good (Blue)  David Guetta;Bebe Rexha   \n",
            "\n",
            "      track_genre  popularity  \n",
            "81051         pop        1.00  \n",
            "20001       dance        1.00  \n",
            "51664     hip-hop        0.99  \n",
            "68303      latino        0.98  \n",
            "81210         pop        0.98  \n",
            "67356       latin        0.98  \n",
            "88410      reggae        0.98  \n",
            "30003         edm        0.98  \n",
            "89411   reggaeton        0.98  \n",
            "20008       dance        0.98  \n"
          ]
        }
      ]
    }
  ]
}